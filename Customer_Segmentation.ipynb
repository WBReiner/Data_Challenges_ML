{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that will parse the date\n",
    "def get_day(x): return dt.datetime(x.year, x.month, x.day) \n",
    "\n",
    "# Create InvoiceDay column\n",
    "online['InvoiceDay'] = online['InvoiceDate'].apply(get_day) \n",
    "\n",
    "# Group by CustomerID and select the InvoiceDay value\n",
    "grouping = online.groupby('CustomerID')['InvoiceDay'] \n",
    "\n",
    "# Assign a minimum InvoiceDay value to the dataset\n",
    "online['CohortDay'] = grouping.transform('min')\n",
    "\n",
    "# View the top 5 rows\n",
    "print(online.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate time offset in days - part 1\n",
    "Calculating time offset for each transaction allows you to report the metrics for each cohort in a comparable fashion.\n",
    "\n",
    "First, we will create 6 variables that capture the integer value of years, months and days for Invoice and Cohort Date using the get_date_int() function that's been already defined for you:\n",
    "\n",
    "def get_date_int(df, column):\n",
    "    year = df[column].dt.year\n",
    "    month = df[column].dt.month\n",
    "    day = df[column].dt.day\n",
    "    return year, month, day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the integers for date parts from the `InvoiceDay` column\n",
    "invoice_year, invoice_month, invoice_day = get_date_int(online, \"InvoiceDay\")\n",
    "\n",
    "# Get the integers for date parts from the `CohortDay` column\n",
    "cohort_year, cohort_month, cohort_day = get_date_int(online, \"CohortDay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate time offset in days - part 2\n",
    "Great work! Now, we have six different data sets with year, month and day values for Invoice and Cohort dates - invoice_year, cohort_year, invoice_month, cohort_month, invoice_day, and cohort_day.\n",
    "\n",
    "In this exercise you will calculate the difference between the Invoice and Cohort dates in years, months and days separately and then calculate the total days difference between the two. This will be your days offset which we will use in the next exercise to visualize the customer count. The online data has been loaded, you can print its header to the console by calling online.head()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate difference in years\n",
    "years_diff = invoice_year - cohort_year\n",
    "\n",
    "# Calculate difference in months\n",
    "months_diff = invoice_month - cohort_month\n",
    "\n",
    "# Calculate difference in days\n",
    "days_diff = invoice_day - cohort_day\n",
    "\n",
    "\n",
    "# Extract the difference in days from all previous values\n",
    "online['CohortIndex'] = years_diff * 365 + months_diff * 30 + days_diff + 1\n",
    "print(online.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customer Retention: The percentage of active customers compared to the total number of customers.\n",
    "\n",
    "### Calculate retention rate from scratch\n",
    "You have seen how to create retention and average quantity metrics table for the monthly acquisition cohorts. Now it's you time to build the retention metrics by yourself.\n",
    "\n",
    "The online dataset has been loaded to you with monthly cohorts and cohort index assigned from this lesson. Feel free to print it in the Console.\n",
    "\n",
    "Also, we have created a loaded a groupby object as grouping DataFrame with this command: grouping = online.groupby(['CohortMonth', 'CohortIndex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of unique values per customer ID\n",
    "cohort_data = grouping[\"CustomerID\"].apply(pd.Series.nunique).reset_index()\n",
    "\n",
    "# Create a pivot \n",
    "cohort_counts = cohort_data.pivot(index=\"CohortMonth\", columns=\"CohortIndex\", values=\"CustomerID\")\n",
    "\n",
    "# Select the first column and store it to cohort_sizes\n",
    "cohort_sizes = cohort_counts.iloc[:,0]\n",
    "\n",
    "# Divide the cohort count by cohort sizes along the rows\n",
    "retention = cohort_counts.divide(cohort_sizes, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate average price\n",
    "You will now calculate the average price metric and analyze if there are any differences in shopping patterns across time and across cohorts.\n",
    "\n",
    "The online dataset has been loaded to you with monthly cohorts and cohort index assigned from this lesson. Feel free to print it to the Console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a groupby object and pass the monthly cohort and cohort index as a list\n",
    "grouping = online.groupby([\"CohortMonth\", \"CohortIndex\"]) \n",
    "\n",
    "# Calculate the average of the unit price column\n",
    "cohort_data = grouping[\"UnitPrice\"].mean()\n",
    "\n",
    "# Reset the index of cohort_data\n",
    "cohort_data = cohort_data.reset_index()\n",
    "\n",
    "# Create a pivot \n",
    "average_quantity = cohort_data.pivot(index=\"CohortMonth\", columns=\"CohortIndex\", values=\"UnitPrice\")\n",
    "print(average_quantity.round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize average quantity metric\n",
    "You are now going to visualize average quantity values in a heatmap.\n",
    "\n",
    "We have loaded pandas package as pd, and the average quantity values DataFrame as average_quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import seaborn package as sns\n",
    "import seaborn as sns\n",
    "\n",
    "# Initialize an 8 by 6 inches plot figure\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "# Add a title\n",
    "plt.title('Average Spend by Monthly Cohorts')\n",
    "\n",
    "# Create the heatmap\n",
    "sns.heatmap(average_quantity, annot=True, cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency, Frequency, Monetary (RFM) segmentation\n",
    "qcut in pandas gets percentile\n",
    "\n",
    "Calculate Spend quartiles (q=4)\n",
    "We have created a dataset for you with random CustomerID and Spend values as data. You will now use this dataset to group customers into quartiles based on Spend values and assign labels to each of them.\n",
    "\n",
    "pandas library as been loaded as pd. Feel free to print the data to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spend quartile with 4 groups - a range between 1 and 5\n",
    "spend_quartile = pd.qcut(data['Spend'], q=4, labels=range(1,5))\n",
    "\n",
    "# Assign the quartile values to the Spend_Quartile column in data\n",
    "data['Spend_Quartile'] = spend_quartile\n",
    "\n",
    "# Print data with sorted Spend values\n",
    "print(data.sort_values(\"Spend\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Recency deciles (q=10)\n",
    "We have created a dataset for you with random CustomerID and Recency_Days values as data. You will now use this dataset to group customers into quartiles based on Recency_Days values and assign labels to each of them.\n",
    "\n",
    "Be cautious about the labels for this exercise. You will see that the labels are inverse, and will required one additional step in separately creating them. If you need to refresh your memory on the process of creating the labels, check out the slides!\n",
    "\n",
    "The pandas library as been loaded as pd. Feel free to print the data to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store labels from 4 to 1 in a decreasing order # -1 dec the order\n",
    "r_labels = list(range(4, 0, -1))\n",
    "\n",
    "# Create a spend quartile with 4 groups and pass the previously created labels \n",
    "recency_quartiles = pd.qcut(data['Recency_Days'], q=4, labels=r_labels)\n",
    "\n",
    "# Assign the quartile values to the Recency_Quartile column in `data`\n",
    "data['Recency_Quartile'] = recency_quartiles \n",
    "\n",
    "# Print `data` with sorted Recency_Days values\n",
    "print(data.sort_values('Recency_Days'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate RFM values\n",
    "Calculate Recency, Frequency and Monetary values for the online dataset we have used before - it has been loaded for you with recent 12 months of data. There's a TotalSum column in the online dataset which has been calculated by multiplying Quantity and UnitPrice: online['Quantity'] * online['UnitPrice'].\n",
    "\n",
    "Also, we have created a snapshot_date variable that you can use to calculate recency. Feel free to print the online dataset and the snapshot_date into the Console. The pandas library is loaded as pd, and datetime as dt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Recency, Frequency and Monetary value for each customer \n",
    "datamart = online.groupby(['CustomerID']).agg({\n",
    "    'InvoiceDate': lambda x: (snapshot_date - x.max()).days,\n",
    "    'InvoiceNo': 'count',\n",
    "    'TotalSum': 'sum'})\n",
    "\n",
    "# Rename the columns \n",
    "datamart.rename(columns={'InvoiceDate': 'Recency',\n",
    "                         'InvoiceNo': 'Frequency',\n",
    "                         'TotalSum': 'MonetaryValue'}, inplace=True)\n",
    "\n",
    "# Print top 5 rows\n",
    "print(datamart.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate 3 groups for Recency and Frequency\n",
    "You will now group the customers into three separate groups based on Recency, and Frequency.\n",
    "\n",
    "The dataset has been loaded as datamart, you can use console to view top rows of it. Also, pandas has been loaded as pd.\n",
    "\n",
    "We will use the result from the exercise in the next one, where you will groups customers based on the MonetaryValue and finally calculate and RFM_Score.\n",
    "\n",
    "Once completed, print the results to the screen to make sure you have successfully created the quartile columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels for Recency and Frequency\n",
    "r_labels = range(3, 0, -1); f_labels = range(1, 4)\n",
    "\n",
    "# Assign these labels to three equal percentile groups \n",
    "r_groups = pd.qcut(datamart['Recency'], q=3, labels=r_labels)\n",
    "\n",
    "# Assign these labels to three equal percentile groups \n",
    "f_groups = pd.qcut(datamart['Frequency'], q=3, labels=f_labels)\n",
    "\n",
    "# Create new columns R and F \n",
    "datamart = datamart.assign(R=r_groups.values, F=f_groups.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate RFM Score\n",
    "Great work, you will now finish the job by assigning customers to three groups based on the MonetaryValue percentiles and then calculate an RFM_Score which is a sum of the R, F, and M values.\n",
    "\n",
    "The datamart has been loaded with the R and F values you have created in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
